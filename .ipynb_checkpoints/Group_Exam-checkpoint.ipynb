{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23010718",
   "metadata": {},
   "source": [
    "Machine learning INF284 Group Exam: Markus, Nikita, Bo og Andre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806075fe",
   "metadata": {},
   "source": [
    "Task 1 Machine learning on tabular mushrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd336a9",
   "metadata": {},
   "source": [
    "Task 2 Sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d1e71",
   "metadata": {},
   "source": [
    "Task 3 Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b2a14",
   "metadata": {},
   "source": [
    "In this task, the assignment is about training a convolutional neural network (CNN) as a binary classifier from the dataset that we have been provided with. This is a CIFAR-10 dataset that consists of 60000 images that are 32x32 colored images and will identify one of the following categories; airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. Each of these has 6000 images that are divided into 50000 for the training model and 10000 for the testing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc13fd",
   "metadata": {},
   "source": [
    "Info Box: Importing Required Libraries\n",
    "\n",
    "In the following code block, we are importing the necessary libraries and modules to build and train the convolutional neural network (CNN) for binary image classification of task 3 using the Dataset of CIFAR-10. The following is a numerated list of imports with further explanations.\n",
    "\n",
    "1. tensorflow: TensorFlow is an open-source machine learning library that helps us define and train neural network models.\n",
    "2. VGG16: VGG16 is a pre-trained CNN architecture, which has proven to be effective for various image recognition tasks. We will use this as the base model for our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378e749",
   "metadata": {},
   "source": [
    "While researching for this assignment we found a couple of different pre-trained CNN models we could use for this project. Some of the choices were ResNet-50/101/152, Inception-v3/v4, MobileNetV1/V2/V3. A decision was made not to use these because of the computing power that would be unsatisfactory for some systems with the amount of layers that the models have. We landed upon the VGG16 model that is a deep CNN model that has 16 layers. It is a less complex model compared to the previous one we have mentioned, but it is more complex then a 3-5 layer CNN. We chose VGG16 at first because we ran into some errors while trying to create our own 3-5 layer CNN using a pre-trained CNN model that has strong performance in particular image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0fca02",
   "metadata": {},
   "source": [
    "3. image: The image module from the Keras preprocessing library helps us load and preprocess images from our dataset.\n",
    "4. Model: This class allows us to create custom models by specifying the input and output layers.\n",
    "5. Dense and GlobalAveragePooling2D: These are Keras layers that we'll use to modify the VGG16 model for our specific task.\n",
    "6. Adam: The Adam optimizer is an optimization algorithm that helps us train our neural network.\n",
    "7. numpy: NumPy is a library for numerical computing in Python. We'll use it for handling arrays and mathematical operations.\n",
    "8. os: The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\n",
    "9. pickle: This module is used for serializing and de-serializing Python objects. We will use it to load the CIFAR-10 dataset.\n",
    "10. matplotlib.pyplot: Matplotlib is a plotting library, and we will use it to visualize our dataset and training results. We will be plotting accuracy and validation loss to see when and if the data plateaus once we start training it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8242c8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 13:36:41.323299: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-26 13:36:41.370828: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-26 13:36:41.596151: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-26 13:36:41.597676: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 13:36:42.476578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff661e",
   "metadata": {},
   "source": [
    "Loading CIFAR-10 Dataset\n",
    "\n",
    "In the following code block, we define a function called unpickle that is going to load our CIFAR-10 dataset files. The dataset is stored in a serialized format using the Python pickle module. This function accepts a file path as input and returns a dictionary containing the loaded data.\n",
    "\n",
    "1. file: The file path of the CIFAR-10 dataset file to load.\n",
    "2. fo: A file object created using the open() function to read the contents of the dataset file.\n",
    "3. dict: A dictionary object containing the deserialized contents of the dataset file.\n",
    "\n",
    "We use this function by simply passing the file path of a CIFAR-10 dataset file to it, and it will return a dictionary containing the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb1c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to load our dataset files\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bea3db",
   "metadata": {},
   "source": [
    "Loading and Preprocessing CIFAR-10 Dataset\n",
    "\n",
    "Further we load the data by defining a function called load_cifar10_data to load and preprocess the CIFAR-10 dataset. This function accepts the path to the data directory containing the dataset files and returns the preprocessed training and testing data along with their corresponding labels.\n",
    "\n",
    "The function performs the following steps:\n",
    "\n",
    "1. Iterate through the data batches 1 to 5 and load each batch using the unpickle function.\n",
    "2. Stack the training data from all batches vertically using np.vstack.\n",
    "3. Load the testing data using the unpickle function.\n",
    "4. Reshape the training and testing data to match the desired dimensions (number of images, height, width, and channels) using numpy.reshape.\n",
    "5. Rearrange the axes to match the format expected by the TensorFlow library using numpy.rollaxis.\n",
    "6. Convert the training and testing labels to NumPy arrays.\n",
    "\n",
    "We use this function by passing the path to the data directory containing the CIFAR-10 dataset files, and it will return the preprocessed training and testing data along with their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38454b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        data_dict = unpickle(os.path.join(data_dir, f'data_batch_{i}'))\n",
    "        if i == 1:\n",
    "            train_data = data_dict[b'data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dict[b'data']))\n",
    "        train_labels += data_dict[b'labels']\n",
    "\n",
    "    test_data_dict = unpickle(os.path.join(data_dir, 'test_batch'))\n",
    "    test_data = test_data_dict[b'data']\n",
    "    test_labels = test_data_dict[b'labels']\n",
    "\n",
    "    train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ed7a0",
   "metadata": {},
   "source": [
    "Loading CIFAR-10 Dataset into Variables\n",
    "\n",
    "Further we are using the load_cifar10_data function to load and preprocess the CIFAR-10 dataset. We provide the data directory containing the dataset files as an argument to the function.\n",
    "\n",
    "The function returns four arrays:\n",
    "\n",
    "1. x_train: The preprocessed training data, a NumPy array of shape (number of training images, height, width, channels).\n",
    "2. y_train: The training labels, a NumPy array of shape (number of training images,).\n",
    "3. x_test: The preprocessed testing data, a NumPy array of shape (number of testing images, height, width, channels).\n",
    "4. y_test: The testing labels, a NumPy array of shape (number of testing images,).\n",
    "\n",
    "We store these arrays in the corresponding variables to use later in our neural network model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb34dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './cifar-10-batches-py/data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16922/2643499439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./cifar-10-batches-py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cifar10_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16922/2934091144.py\u001b[0m in \u001b[0;36mload_cifar10_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'data_batch_{i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16922/3973288415.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the function to load our dataset files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cifar-10-batches-py/data_batch_1'"
     ]
    }
   ],
   "source": [
    "data_dir = './cifar-10-batches-py'\n",
    "x_train, y_train, x_test, y_test = load_cifar10_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66af2e6",
   "metadata": {},
   "source": [
    "Preprocessing and Normalizing Input Data\n",
    "\n",
    "In this code block, we perform further preprocessing on the input data and normalize the pixel values for both the training and testing sets.\n",
    "\n",
    "We divide the pixel values by 255 to scale them to the range [0, 1]. This normalization helps improve the training process by ensuring that the input values are within a similar scale.\n",
    "\n",
    "We choose a category (in this case, 0) for our binary classification task.\n",
    "\n",
    "We convert the class labels for both training and testing sets to one-hot encoded vectors using the tf.keras.utils.to_categorical function. One-hot encoding is a representation method where the index of the target class is set to 1 and the remaining indices are set to 0. This is a preprocessing step for multi-class classification problems.\n",
    "\n",
    "By normalizing the input data and converting the class labels to one-hot encoding, we prepare our dataset for training the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa65d036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess input data, and normalize the input data \n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "chosen_category = 0\n",
    "\n",
    "# Convert class labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a21e46",
   "metadata": {},
   "source": [
    "Plotting Validation Loss\n",
    "\n",
    "Here we define a function called plot_validation_loss to visualize the validation loss during the training process. This function accepts the training history object returned by the fit method when training a Keras model and generates a plot of the validation loss over epochs.\n",
    "\n",
    "The function performs the following steps:\n",
    "\n",
    "1. Use the plt.plot function to create a line plot of the validation loss stored in history.history['val_loss'].\n",
    "2. Set the title, x-axis label, and y-axis label for the plot using plt.title, plt.xlabel, and plt.ylabel functions.\n",
    "3. Add a legend to the plot using the plt.legend function, specifying the location of the legend as the upper right corner.\n",
    "4. Display the plot using the plt.show function.\n",
    "\n",
    "You can use this function to analyze the training process and identify any issues, such as overfitting or underfitting, based on the validation loss curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot validation loss\n",
    "def plot_validation_loss(history):\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da66f51",
   "metadata": {},
   "source": [
    "Info Box: Loading the Pre-trained VGG16 Model\n",
    "\n",
    "In the following code block we load the pre-trained VGG16 model using the VGG16 function from the tensorflow.keras.applications module. We will use this pre-trained model as the base for our binary image classifier.\n",
    "\n",
    "The VGG16 function accepts the following arguments:\n",
    "\n",
    "1. weights: The pre-trained weights to load. In this case, we use the 'imagenet' weights, which were trained on the ImageNet dataset.\n",
    "2. include_top: A boolean value indicating whether to include the fully connected layers at the top of the network. We set this to False to exclude the original classification layer, as we will add our custom binary classification layer later.\n",
    "3. input_shape: The shape of the input tensor. We provide a tuple with the desired input shape (32, 32, 3) since the CIFAR-10 images have a resolution of 32x32 pixels and 3 color channels.\n",
    "\n",
    "After loading the VGG16 model, we store it in the base_model variable, which we will use to build our custom binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576fab6",
   "metadata": {},
   "source": [
    "Info Box: Modifying the VGG16 Model for Binary Classification\n",
    "\n",
    "In this code block, we modify the pre-trained VGG16 model to create our binary image classifier. We follow these steps:\n",
    "\n",
    "Add a global spatial average pooling layer: We take the output of the base VGG16 model (base_model.output) and pass it through a GlobalAveragePooling2D layer. This layer reduces the spatial dimensions of the feature maps by computing the average of all values in each channel. This operation significantly reduces the number of parameters and helps prevent overfitting.\n",
    "\n",
    "Add a fully connected layer: We add a Dense layer with 1024 units and a ReLU activation function. This layer will learn higher-level features from the pooled feature maps.\n",
    "\n",
    "Add the final output layer for binary classification: We replace the original 10-class softmax activation output layer with a single-unit Dense layer with a sigmoid activation function. The sigmoid activation function outputs a value between 0 and 1, representing the probability that the input image belongs to the chosen category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ddc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add the final output layer for 10-class classification\n",
    "# predictions = Dense(10, activation='softmax')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune only the top layers (freeze all convolutional layers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the validation loss\n",
    "plot_validation_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff88195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a new image and preprocess it\n",
    "new_image_path = './new_images/picture_1.png'# Here is the pathing for the image so if you want to add an image just past it into this folder and change the name.\n",
    "new_image = image.load_img(new_image_path, target_size=(32, 32))\n",
    "new_image = image.img_to_array(new_image)\n",
    "new_image = np.expand_dims(new_image, axis=0)\n",
    "new_image = new_image / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af343d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class of the new image\n",
    "prediction = model.predict(new_image)\n",
    "predicted_class = 1 if prediction[0][0] > 0.5 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c280f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "if predicted_class:\n",
    "    print(f\"The image is predicted to be an {categories[chosen_category]}.\")\n",
    "else:\n",
    "    print(f\"The image is predicted to not be an {categories[chosen_category]}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
