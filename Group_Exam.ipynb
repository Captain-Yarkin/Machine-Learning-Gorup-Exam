{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806075fe",
   "metadata": {},
   "source": [
    "# Task 1 Machine learning on tabular mushrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd336a9",
   "metadata": {},
   "source": [
    "# Task 2 Sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d1e71",
   "metadata": {},
   "source": [
    "# Task 3 Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b2a14",
   "metadata": {},
   "source": [
    "In this task, the assignment is about training a convolutional neural network (CNN) as a binary classifier from the dataset that we have been provided with. This is a CIFAR-10 dataset that consists of 60000 images that are 32x32 colored images and will identify one of the following categories; airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. Each of these has 6000 images that are divided into 50000 for the training model and 10000 for the testing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc13fd",
   "metadata": {},
   "source": [
    "In the following code block, we are importing the necessary libraries and modules to build and train the convolutional neural network (CNN) for binary image classification using the Dataset of CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378e749",
   "metadata": {},
   "source": [
    "While researching for this assignment we found a couple of different pre-trained CNN models we could use for this project. Some of the choices were ResNet-50/101/152, Inception-v3/v4, MobileNetV1/V2/V3. We decided not to use these because of the computing power that would be unsatisfactory for some systems with the amount of layers that the models have. We landed upon the VGG16 model that is a deep CNN model that has 16 layers. It is a less complex model compared to the previous ones we have mentioned, but it is more complex then a 3-5 layer CNN. We chose VGG16 at first because we ran into some errors while trying to create our own 3-5 layer CNN using a pre-trained CNN model that has strong performance in particular image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8242c8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 11:15:26.677298: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-02 11:15:26.714365: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-02 11:15:26.911612: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-02 11:15:26.912398: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-02 11:15:27.849597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff661e",
   "metadata": {},
   "source": [
    "The code block defines the unpickle function to load CIFAR-10 dataset files, which are serialized using Python's pickle module. The function takes a file path as input, reads the dataset file, and returns a dictionary with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb1c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to load our dataset files\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bea3db",
   "metadata": {},
   "source": [
    "Loading and Preprocessing CIFAR-10 Dataset\n",
    "\n",
    "The `load_cifar10_data` function loads and preprocesses the CIFAR-10 dataset so that we can apply it to our CNN later. It takes the path to the data directory and returns preprocessed training and testing data with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38454b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        data_dict = unpickle(os.path.join(data_dir, f'data_batch_{i}'))\n",
    "        if i == 1:\n",
    "            train_data = data_dict[b'data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dict[b'data']))\n",
    "        train_labels += data_dict[b'labels']\n",
    "\n",
    "    test_data_dict = unpickle(os.path.join(data_dir, 'test_batch'))\n",
    "    test_data = test_data_dict[b'data']\n",
    "    test_labels = test_data_dict[b'labels']\n",
    "\n",
    "    train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ed7a0",
   "metadata": {},
   "source": [
    "Loading CIFAR-10 Dataset into Variables\n",
    "\n",
    "We use load_cifar10_data to load and preprocess the CIFAR-10 dataset. These arrays are stored in corresponding variables for later use in the neural network model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb34dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './cifar-10-batches-py'\n",
    "x_train, y_train, x_test, y_test = load_cifar10_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66af2e6",
   "metadata": {},
   "source": [
    "Preprocessing and Normalizing Input Data\n",
    "\n",
    "In this step, we preprocess input data by:\n",
    "\n",
    "1. We divide and the pixel values by 225 and normalizing them to the range [0, 1]. This normalization helps improve the training process by ensuring that the input values are within a similar scale.\n",
    "2. Choosing a category for binary classification.\n",
    "3. Converting class labels to one-hot encoding using tf.keras.utils.to_categorical.\n",
    "\n",
    "This prepares the dataset for training the CNN model by ensuring input values are within a similar scale and using one-hot encoding for our 2 categories that we have later of [\"not airplane\", \"airplane\"].\n",
    "\n",
    "By normalizing the input data and converting the class labels to one-hot encoding, we prepare our dataset for training the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa65d036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess input data, and normalize the input data \n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "chosen_category = 0\n",
    "\n",
    "# Convert class labels to one-hot encoding\n",
    "y_train = np.where(y_train == chosen_category, 1, 0)\n",
    "y_test = np.where(y_test == chosen_category, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a21e46",
   "metadata": {},
   "source": [
    "Plotting Validation Loss\n",
    "\n",
    "The function plot_validation_loss visualizes the validation loss during training. It takes the training history object from the model's fit method and generates a plot of validation loss over epochs.\n",
    "\n",
    "We are going to use this function to analyze the training process and identify any issues, such as overfitting or underfitting, based on the validation loss curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f266eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot validation loss\n",
    "def plot_validation_loss(history):\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6aa63e",
   "metadata": {},
   "source": [
    "Plotting Model Accuracy\n",
    "\n",
    "The `plot_accuracy(history)` function plots training and validation accuracy over epochs. It takes the training history object from the model's `fit` method.\n",
    "\n",
    "The plot helps further observe the model's performance and identify potential gaps between training and validation accuracy curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73c84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da66f51",
   "metadata": {},
   "source": [
    "Loading Pre-trained VGG16 Model\n",
    "\n",
    "The code block loads the pre-trained VGG16 model using `tensorflow.keras.applications.VGG16` as the base for a binary image classifier.\n",
    "\n",
    "Arguments for VGG16 function:\n",
    "1. `weights`: 'imagenet' weights, trained on ImageNet dataset.\n",
    "2. `include_top`: Set to False to exclude original classification layer, as a custom binary classification layer will be added.\n",
    "3. `input_shape`: Tuple with input shape (32, 32, 3) for CIFAR-10 images. 32x32 pixels size with 3 color channels\n",
    "\n",
    "The loaded VGG16 model is stored in the `base_model` variable to build the custom binary classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48f24e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 11:15:30.378314: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576fab6",
   "metadata": {},
   "source": [
    "Modifying VGG16 Model for Binary Classification\n",
    "\n",
    "Here we modify the pre-trained VGG16 model to create a binary image classifier:\n",
    "\n",
    "1. Add a GlobalAveragePooling2D layer to reduce spatial dimensions of feature maps, preventing our model to be overfitted.\n",
    "2. Add a Dense layer with 1024 units and ReLU activation to learn higher-level features.\n",
    "3. Change the output layer to a single unit with sigmoid activation for binary classification. The sigmoid function outputs a probability for the input image belonging to the chosen category which is [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8ddc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add the final output layer for 10-class classification\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a09ac26",
   "metadata": {},
   "source": [
    "Fine-tuning Custom Binary Classifier Model\n",
    "\n",
    "Here we fine-tune the binary classifier on the dataset:\n",
    "\n",
    "1. Freeze Convolutional Layers: Set the trainable attribute of the VGG16 base model layers to False, so only the added fully connected layers are trained, speeding up the process.\n",
    "2. Compile the Model: Use the Adam optimizer with a 0.0001 learning rate, 'binary_crossentropy' loss, and 'accuracy' as the evaluation metric. We are using 0.0001 learning rate to Preserve pre-trained features that ensures we don't make drastic updates that could degrade the model's performance, more stable convergence, preventing overshooting optimal weights and learning slowly helps the model generalize better, reducing overfitting.\n",
    "3. Train the Model: Train using the preprocessed CIFAR-10 dataset with x_train, y_train, and 5 epochs. Monitor performance using x_test and y_test as validation data.\n",
    "\n",
    "The training history is stored for plotting accuracy and loss over time, helping identify model performance and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a6a2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  95/1563 [>.............................] - ETA: 2:25 - loss: 0.3150 - accuracy: 0.8924"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37037/2624734166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fine-tune only the top layers (freeze all convolutional layers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2711d7e",
   "metadata": {},
   "source": [
    "Plotting Validation Loss\n",
    "\n",
    "Using the `plot_validation_loss(history)` function, we plot the validation loss over training epochs. The history variable holds training information, including validation loss per epoch.\n",
    "\n",
    "By analyzing the plot, we can assess how well the model generalizes to unseen data.\n",
    "\n",
    "Despite using 5 to 25 epochs, the model did not converge but still provided correct binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515e807",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the validation loss\n",
    "plot_validation_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ceb88c",
   "metadata": {},
   "source": [
    "Plotting Model Accuracy\n",
    "\n",
    "We use the `plot_accuracy(history)` function to visualize training and validation accuracy over training epochs. The history variable holds training information, including accuracy per epoch.\n",
    "\n",
    "The function plots the training and validation accuracy, displaying the model's performance. By examining the plot, we can assess the model's performance and identify further issues based on the gap between the curves. A well-performing model should have a smaller gap and high accuracy on both sets, indicating effective learning and good generalization to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a64ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy\n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5cf55",
   "metadata": {},
   "source": [
    "Loading and Preprocessing a New Image\n",
    "\n",
    "To load and preprocess a new image for classification:\n",
    "\n",
    "1. Load New Image: The image needs to be resized so that it matches the model's input size (32 x 32 pixels).\n",
    "2. Normalize the Image: Divide the image's pixel values by 255.0 to normalize it, ensuring pixel values are in the same 0 to 1 range as the training data.\n",
    "\n",
    "The new image is now ready for classification by the model. We have tested that the images are the images are the same format. We prefered using pngs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff88195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a new image and preprocess it\n",
    "new_image_path = './new_images/picture_1.png'# Here is the pathing for the image so if you want to add an image just past it into this folder and change the name.\n",
    "new_image = image.load_img(new_image_path, target_size=(32, 32))\n",
    "new_image = image.img_to_array(new_image)\n",
    "new_image = np.expand_dims(new_image, axis=0)\n",
    "new_image = new_image / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca72ff2",
   "metadata": {},
   "source": [
    "Predicting the Class of a New Image\n",
    "\n",
    "To predict the class of a preprocessed new image using the trained model:\n",
    "\n",
    "1. Predict the Class: Use `model.predict()` to predict the class, which returns the predicted probability for the positive class (chosen category).\n",
    "\n",
    "2. Determine the Predicted Class: Set a 0.5 threshold for deciding the predicted class. If the predicted probability is above 0.5, assign the positive class (1); otherwise, assign the negative class (0).\n",
    "\n",
    "`predicted_class` now contains the predicted class of the new image, indicating if the model classified the image as part of the chosen category or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af343d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class of the new image\n",
    "prediction = model.predict(new_image)\n",
    "predicted_class = 1 if prediction[0][0] > 0.5 else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9605ffd",
   "metadata": {},
   "source": [
    "Displaying the Predicted Class\n",
    "\n",
    "We categories our binary values of ['not airplane', 'airplane']\n",
    "\n",
    "This prints outs an output, showing if the model classified the new image as part of the chosen category (airplane) or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd64aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['not airplane', 'airplane']\n",
    "print(f\"The image is predicted to be {categories[predicted_class]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6023c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
